{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Immune-Enhanced Machine Learning Approach for Early Detection of Precancerous Colorectal Neoplasia: \n",
    "Insights from Biomarkers in Routine Health Checkups\n",
    "\n",
    "Author      : Yohan Kim\n",
    "Date        : 2025-08-08\n",
    "Email       : biologyohan@gmail.com\n",
    "Organization: MIH Lab, CHA University\n",
    "\"\"\"\n",
    "\n",
    "# ========== Library Imports ==========\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_recall_curve, auc, \n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import random\n",
    "\n",
    "# ========== Reproducibility Setting ==========\n",
    "seed = 417\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ========== File and Data Path Setting ==========\n",
    "data_folder = '/data/yohan/nkcell/'\n",
    "file_names = [\n",
    "    'Biopsy_Yes_key_6146_feature27_threshold200.xlsx'\n",
    "]\n",
    "output_vars = ['nofadvneoplasm', 'computedhighrisk']\n",
    "output_var = 'computedhighrisk'\n",
    "\n",
    "# Output folder for saving evaluation results\n",
    "base_output_path = '/data/yohan/nkcell/results'\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "output_dir = os.path.join(base_output_path, timestamp)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ========== Device Setting ==========\n",
    "device_name = 'cuda:3' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device in use: {device_name}\")\n",
    "\n",
    "# ========== Model Definition ==========\n",
    "models = {'TabNet': TabNetClassifier}\n",
    "\n",
    "# Define hyperparameter search space (manual grid search)\n",
    "param_distributions = {\n",
    "    'TabNet': {\n",
    "        'n_d': [8], # 8 16 32 64\n",
    "        'n_a': [8], # 8 16 32 64\n",
    "        'n_steps': [7], # 3 5 7\n",
    "        'optimizer_params': [{'lr': 0.02}] # 0.01, 0.001...\n",
    "    }\n",
    "}\n",
    "\n",
    "# ========== Main Loop for Each File ==========\n",
    "for file_name in file_names:\n",
    "    print(f\"\\n=== Processing File: {file_name} ===\")\n",
    "    base_file_name = os.path.splitext(file_name)[0]  \n",
    "    file_path = os.path.join(data_folder, file_name)\n",
    "    data = pd.read_excel(file_path)\n",
    "\n",
    "    # Select input features and target\n",
    "    input_vars = ['age', 'sex', 'totalcholesterol', 'diabetes', 'circum', 'smokingscore', 'drinkingscore', 'wbc', 'plt', 'nkatertiary']\n",
    "    X_raw = data[input_vars].copy()\n",
    "    Y = data[output_var].copy()\n",
    "    X = pd.DataFrame(X_raw, columns=[c.replace(' ', '_') for c in input_vars])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    thresholds = np.linspace(0, 1, 101)  \n",
    "\n",
    "    best_params = {}\n",
    "    model_fold_results = {}  \n",
    "\n",
    "    # ========== Hyperparameter Tuning ==========\n",
    "    for model_name, model_cls in models.items():\n",
    "        print(f\"\\n[Hyperparameter Tuning: {model_name}]\")\n",
    "        param_grid = param_distributions.get(model_name, {})\n",
    "        param_keys = list(param_grid.keys())\n",
    "\n",
    "        best_mean_auc = -1.0\n",
    "        best_param_dict = {}\n",
    "        best_fold_predictions = None\n",
    "\n",
    "        all_param_values = [param_grid[k] for k in param_keys]\n",
    "        for param_combination in product(*all_param_values):\n",
    "            current_params = dict(zip(param_keys, param_combination))\n",
    "\n",
    "            fold_aucs = []\n",
    "            fold_pred_results = []  \n",
    "\n",
    "            for train_idx, valid_idx in skf.split(X, Y):\n",
    "                # Normalization\n",
    "                scaler = MinMaxScaler()\n",
    "                X_train_fold, X_valid_fold = scaler.fit_transform(X.iloc[train_idx]), scaler.transform(X.iloc[valid_idx])\n",
    "                Y_train_fold, Y_valid_fold = Y.iloc[train_idx], Y.iloc[valid_idx]\n",
    "\n",
    "                # Initialize model with learning rate scheduler\n",
    "                model_temp = model_cls(\n",
    "                    device_name=device_name,  \n",
    "                    scheduler_params={\"step_size\":10, \"gamma\":0.9}, \n",
    "                    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                    verbose=0,\n",
    "                    **current_params\n",
    "                )\n",
    "\n",
    "                # Cost-sensitive learning: class weights (inverse frequency)\n",
    "                classes = np.unique(Y_train_fold)\n",
    "                class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=Y_train_fold)\n",
    "                class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device_name)  # GPU에 올리기\n",
    "\n",
    "                # Train model\n",
    "                model_temp.fit(\n",
    "                    X_train_fold, Y_train_fold.values,\n",
    "                    eval_set=[(X_valid_fold, Y_valid_fold.values)],\n",
    "                    patience=20,  \n",
    "                    max_epochs=1000,  \n",
    "                    eval_metric=['auc'],\n",
    "                    loss_fn=nn.CrossEntropyLoss(weight=class_weights_tensor) \n",
    "                )\n",
    "\n",
    "                Y_proba_valid = model_temp.predict_proba(X_valid_fold)[:, 1]\n",
    "                fold_aucs.append(roc_auc_score(Y_valid_fold, Y_proba_valid))\n",
    "                fold_pred_results.append((Y_valid_fold.values, Y_proba_valid))\n",
    "\n",
    "            # Select best hyperparameter set based on mean AUC\n",
    "            mean_auc = np.mean(fold_aucs)\n",
    "            if mean_auc > best_mean_auc:\n",
    "                best_mean_auc = mean_auc\n",
    "                best_param_dict = current_params\n",
    "                best_fold_predictions = fold_pred_results\n",
    "\n",
    "        best_params[model_name] = best_param_dict\n",
    "        model_fold_results[model_name] = best_fold_predictions\n",
    "\n",
    "        print(f\"   -> Best Parameters: {best_param_dict}\")\n",
    "        print(f\"   -> Mean AUC (5-fold): {best_mean_auc:.3f}\")\n",
    "\n",
    "    # ========== Evaluation with Best Parameters ==========\n",
    "    overall_results = []\n",
    "\n",
    "    for model_name, fold_predictions in model_fold_results.items():\n",
    "        print(f\"\\n=== Final Evaluation for Model: {model_name} ===\")\n",
    "\n",
    "        all_y_true = np.concatenate([fp[0] for fp in fold_predictions])\n",
    "        all_y_proba = np.concatenate([fp[1] for fp in fold_predictions])\n",
    "\n",
    "        threshold_metrics = []\n",
    "        for thr in thresholds:\n",
    "            fold_measures = []\n",
    "            for (y_true_fold, y_proba_fold) in fold_predictions:\n",
    "                y_pred_fold = (y_proba_fold >= thr).astype(int)\n",
    "\n",
    "                cm = confusion_matrix(y_true_fold, y_pred_fold)\n",
    "                tp = cm[1, 1]\n",
    "                tn = cm[0, 0]\n",
    "                fp = cm[0, 1]\n",
    "                fn = cm[1, 0]\n",
    "\n",
    "                sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                ppv         = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "                npv         = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "\n",
    "                roc_val_fold = roc_auc_score(y_true_fold, y_proba_fold)\n",
    "                prec_fold, rec_fold, _ = precision_recall_curve(y_true_fold, y_proba_fold)\n",
    "                pr_val_fold = auc(rec_fold, prec_fold)\n",
    "\n",
    "                youden_j = sensitivity + specificity - 1\n",
    "                fold_measures.append([\n",
    "                    sensitivity, specificity, ppv, npv,\n",
    "                    roc_val_fold, pr_val_fold, youden_j\n",
    "                ])\n",
    "\n",
    "            avg_vals = np.mean(fold_measures, axis=0)\n",
    "            std_vals = np.std(fold_measures, axis=0)\n",
    "            threshold_metrics.append([thr, *avg_vals, *std_vals])\n",
    "\n",
    "        columns = [\n",
    "            'Threshold',\n",
    "            'Sensitivity', 'Specificity', 'PPV', 'NPV', 'ROC-AUC', 'PR-AUC', 'Youden',\n",
    "            'Sensitivity_STD', 'Specificity_STD', 'PPV_STD', 'NPV_STD', 'ROC-AUC_STD', 'PR-AUC_STD', 'Youden_STD'\n",
    "        ]\n",
    "        threshold_df = pd.DataFrame(threshold_metrics, columns=columns)\n",
    "\n",
    "        # Select optimal threshold using Youden's index\n",
    "        best_idx = threshold_df['Youden'].idxmax()\n",
    "        optimal_threshold = threshold_df.loc[best_idx, 'Threshold']\n",
    "        print(f\"   -> Optimal Threshold (Youden's index): {optimal_threshold:.3f}\")\n",
    "\n",
    "        # Plot and save Confusion Matrix per fold\n",
    "        for fold_idx, (y_true_fold, y_proba_fold) in enumerate(fold_predictions):\n",
    "            y_pred_fold = (y_proba_fold >= optimal_threshold).astype(int)\n",
    "\n",
    "            cm = confusion_matrix(y_true_fold, y_pred_fold)\n",
    "            plt.figure(figsize=(5,4))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f\"[{model_name}] CM - Fold {fold_idx+1}\\n\"\n",
    "                      f\"Threshold={optimal_threshold:.2f}, {base_file_name}\")\n",
    "            plt.xlabel(\"Predicted\"); \n",
    "            plt.ylabel(\"Actual\")\n",
    "\n",
    "            cm_img = os.path.join(\n",
    "                output_dir, \n",
    "                f\"ConfMat_{model_name}_Fold{fold_idx+1}_{base_file_name}.png\"\n",
    "            )\n",
    "            plt.savefig(cm_img)\n",
    "            plt.close()\n",
    "\n",
    "        # Save summary metrics\n",
    "        row_opt = threshold_df.loc[best_idx]\n",
    "        overall_results.append([\n",
    "            file_name,\n",
    "            model_name,\n",
    "            f\"{optimal_threshold:.3f}\",\n",
    "            f\"{row_opt['Sensitivity']:.3f} ± {row_opt['Sensitivity_STD']:.3f}\",\n",
    "            f\"{row_opt['Specificity']:.3f} ± {row_opt['Specificity_STD']:.3f}\",\n",
    "            f\"{row_opt['PPV']:.3f} ± {row_opt['PPV_STD']:.3f}\",\n",
    "            f\"{row_opt['NPV']:.3f} ± {row_opt['NPV_STD']:.3f}\",\n",
    "            f\"{row_opt['ROC-AUC']:.3f} ± {row_opt['ROC-AUC_STD']:.3f}\",\n",
    "            f\"{row_opt['PR-AUC']:.3f} ± {row_opt['PR-AUC_STD']:.3f}\",\n",
    "            f\"{row_opt['Youden']:.3f} ± {row_opt['Youden_STD']:.3f}\"\n",
    "        ])\n",
    "\n",
    "        # Plot ROC curve\n",
    "        fpr, tpr, _ = roc_curve(all_y_true, all_y_proba)\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.plot(fpr, tpr, label=f\"ROC (AUC={row_opt['ROC-AUC']:.3f})\")\n",
    "        plt.plot([0,1], [0,1], '--', color='gray')\n",
    "        plt.title(f\"[{model_name}] ROC - {base_file_name}\")\n",
    "        plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(os.path.join(output_dir, f\"ROC_Curve_{model_name}_{base_file_name}.png\"))\n",
    "        plt.show()\n",
    "\n",
    "        # Plot PR curve\n",
    "        prec_all, rec_all, _ = precision_recall_curve(all_y_true, all_y_proba)\n",
    "        plt.figure(figsize=(6,5))\n",
    "        plt.plot(rec_all, prec_all, label=f\"PR (AUC={row_opt['PR-AUC']:.3f})\")\n",
    "        plt.title(f\"[{model_name}] PR - {base_file_name}\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.savefig(os.path.join(output_dir, f\"PR_Curve_{model_name}_{base_file_name}.png\"))\n",
    "        plt.show()\n",
    "\n",
    "    # Save final summary table\n",
    "    results_df = pd.DataFrame(overall_results, columns=[\n",
    "        'File','Model','OptimalThreshold',\n",
    "        'Sensitivity','Specificity','PPV','NPV',\n",
    "        'ROC-AUC','PR-AUC','Youden'\n",
    "    ])\n",
    "    csv_path = os.path.join(output_dir, f\"final_results_{base_file_name}.csv\")\n",
    "    results_df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "    print(f\"   -> Final results saved to: {csv_path}\")\n",
    "\n",
    "print(\"\\nAll processes completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
